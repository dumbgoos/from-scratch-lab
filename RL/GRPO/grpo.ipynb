{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e0daa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from typing import Tuple, List, Dict\n",
    "from dataclasses import dataclass\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6391bf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TokenStep:\n",
    "    token_id: int\n",
    "    token_text: str\n",
    "    log_prob: float\n",
    "    position: int\n",
    "\n",
    "@dataclass\n",
    "class Trajectory:\n",
    "    query: str\n",
    "    token_steps: List[TokenStep]\n",
    "    generated_text: str\n",
    "    reward: float\n",
    "    final_answer: str\n",
    "    full_input_ids: List[int] # 完整的输入序列(包含prompt + generated + information)\n",
    "    generated_positions: List[int] # 每个生成 token 在序列中的预测位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6aece73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchEngine:\n",
    "    \"\"\"\n",
    "    搜索引擎\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.knowledge_base = {\n",
    "            \"Luoling\": \"Luoling is a person.\",\n",
    "            \"Chaofa Yuan\": \"Chaofa Yuan is a LLM engineer.\",\n",
    "            \"machine learning\": \"Machine learning is a subset of AI that enables computers to learn from experience.\",\n",
    "            \"neural networks\": \"Neural networks are computing systems inspired by biological neural networks.\",\n",
    "            \"deep learning\": \"Deep learning is a subset of machine learning using artificial neural networks.\",\n",
    "            \"transformer\": \"Transformers are neural network architectures using self-attention mechanisms.\",\n",
    "            \"reinforcement learning\": \"Reinforcement learning involves agents learning through environment interaction.\",\n",
    "        }\n",
    "    def search(self, query: str) -> str:\n",
    "        query_lower = query.lower().strip()\n",
    "        for key, value in self.knowledge_base.items():\n",
    "            if key in query_lower:\n",
    "                return value\n",
    "        return f\"No information found for: {query}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1f701e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchR1GRPO:\n",
    "    def __init__(\n",
    "        self, model_name: str='/root/GRPO/Qwen2.5-0.5B-Instruct', lr: float = 5e-6\n",
    "    ):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "        # 添加特殊 tokens\n",
    "        special_tokens = [\n",
    "            \"<think>\",\n",
    "            \"</think>\",\n",
    "            \"<search>\",\n",
    "            \"</search>\",\n",
    "            \"<information>\",\n",
    "            \"</information>\",\n",
    "            \"<answer>\",\n",
    "            \"</answer>\",\n",
    "        ]\n",
    "\n",
    "        self.tokenizer.add_special_tokens({\"additional_special_tokens\": special_tokens})\n",
    "        self.model.resize_token_embeddings(len(self.tokenizer))\n",
    "\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        \n",
    "        self.model.to(self.device)\n",
    "\n",
    "        # GRPO参数\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
    "        self.beta = 0.01 # kl 散度系数\n",
    "        self.clip_epsilon = 0.2\n",
    "\n",
    "        self.search_engine = SearchEngine()\n",
    "        \n",
    "        # 特殊 token IDs\n",
    "        self.special_token_ids = {\n",
    "            \"<think>\": self.tokenizer.convert_tokens_to_ids(\"<think>\"),\n",
    "            \"</think>\": self.tokenizer.convert_tokens_to_ids(\"</think>\"),\n",
    "            \"<search>\": self.tokenizer.convert_tokens_to_ids(\"<search>\"),\n",
    "            \"</search>\": self.tokenizer.convert_tokens_to_ids(\"</search>\"),\n",
    "            \"<information>\": self.tokenizer.convert_tokens_to_ids(\"<information>\"),\n",
    "            \"</information>\": self.tokenizer.convert_tokens_to_ids(\"</information>\"),\n",
    "            \"<answer>\": self.tokenizer.convert_tokens_to_ids(\"<answer>\"),\n",
    "            \"</answer>\": self.tokenizer.convert_tokens_to_ids(\"</answer>\"),\n",
    "        }\n",
    "    \n",
    "    def generate_trajectory(self, query: str, max_tokens: int=150) -> Trajectory:\n",
    "        \"生成轨迹 - 每个token为一个动作\"\n",
    "        self.model.eval()\n",
    "\n",
    "        # prompt\n",
    "        prompt = f\"\"\"<|im_start|>system\n",
    "            You are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n",
    "            <|im_start|>user\n",
    "            Before you anwer question. You should put think content between `<think>` and `</think>` XML TAG. \n",
    "            If you can not answer it directly, putting search query between `<search>` and `</search>` XML TAG。\n",
    "            Then puttting answer bwtween `<answer>` and `</answer>` XML TAG.\n",
    "\n",
    "            Question: {query}\n",
    "            <|im_end|>\n",
    "            <|im_start|>assistant\n",
    "            \"\"\"\n",
    "        \n",
    "        input_ids = self.tokenizer.encode(prompt, return_tensors='pt').to(self.device)\n",
    "\n",
    "        token_steps = []\n",
    "        generated_tokens = []\n",
    "        current_text = prompt\n",
    "\n",
    "        # 用于保存完整序列和位置信息\n",
    "        full_input_ids = self.tokenizer.encode(prompt, add_special_tokens=False)\n",
    "        generated_positions = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for step in range(max_tokens):\n",
    "                # forward\n",
    "                outputs = self.model(input_ids)\n",
    "                logits = outputs.logits[0, -1, :] # 最后一个logits\n",
    "\n",
    "                # 概率分布\n",
    "                probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "                # 采样下一个token\n",
    "                token_dist = torch.distributions.Categorical(probs)\n",
    "                next_token_id = token_dist.sample()\n",
    "                log_prob = token_dist.log_prob(next_token_id).item()\n",
    "\n",
    "                # decode\n",
    "                token_text = self.tokenizer.decode(\n",
    "                    [next_token_id], skip_special_tokens=False\n",
    "                )\n",
    "\n",
    "                # 记录当前位置\n",
    "                generated_positions.append(len(full_input_ids) - 1)\n",
    "\n",
    "                # 记录步骤\n",
    "                token_step = TokenStep(\n",
    "                    token_id=next_token_id.item(),\n",
    "                    token_text=token_text,\n",
    "                    log_prob=log_prob,\n",
    "                    position=step\n",
    "                )\n",
    "\n",
    "                token_steps.append(token_step)\n",
    "                generated_tokens.append(next_token_id.item())\n",
    "\n",
    "                # 更新输入和完整序列\n",
    "                input_ids = torch.cat(\n",
    "                    [input_ids, next_token_id.unsqueeze(0).unsqueeze(0)], dim=1\n",
    "                )\n",
    "                full_input_ids.append(next_token_id.item())\n",
    "                current_text += token_text\n",
    "\n",
    "                if next_token_id.item() == self.special_token_ids[\"</search>\"]:\n",
    "                    search_query = self.extract_search_query(current_text)\n",
    "                    if search_query:\n",
    "                        search_result = self.search_engine.search(search_query)\n",
    "                        info_text = f\"\\n<information>{search_result}</information>\\n\"\n",
    "                        info_tokens = self.tokenizer.encode(\n",
    "                            info_text, add_special_tokens=False\n",
    "                        )\n",
    "\n",
    "                        # 搜索结果加入输入：\n",
    "                        info_tensor = (\n",
    "                            torch.tensor(info_tokens).unsqueeze(0).to(self.device)\n",
    "                        )\n",
    "                        input_ids = torch.cat([input_ids, info_tensor], dim=1)\n",
    "                        full_input_ids.extend(info_tokens)\n",
    "                        current_text += info_text\n",
    "                \n",
    "                if next_token_id.item() == self.special_token_ids['</answer>']:\n",
    "                    break\n",
    "\n",
    "                # 其他结束条件\n",
    "                if (\n",
    "                    next_token_id.item() == self.tokenizer.eos_token_id\n",
    "                    or step >= max_tokens - 1\n",
    "                ):\n",
    "                    break\n",
    "        # 完整文本\n",
    "        generated_text  = self.tokenizer.decode(\n",
    "            generated_tokens, skip_special_tokens=False\n",
    "        )\n",
    "        final_answer = self.extract_final_answer(generated_text)\n",
    "\n",
    "\n",
    "        return Trajectory(\n",
    "            query=query,\n",
    "            token_steps=token_steps,\n",
    "            generated_text=generated_text,\n",
    "            reward=0.0,  # 稍后计算\n",
    "            final_answer=final_answer,\n",
    "            full_input_ids=full_input_ids,\n",
    "            generated_positions=generated_positions,\n",
    "        )\n",
    "\n",
    "\n",
    "    def extract_search_query(self, text: str) -> str:\n",
    "        \"\"\"从文本中提取搜索查询\"\"\"\n",
    "        # 查找最后一个 <search>...</search> 块\n",
    "        pattern = r\"<search>(.*?)</search>\"\n",
    "        matches = re.findall(pattern, text, re.DOTALL)\n",
    "        if matches:\n",
    "            return matches[-1].strip()\n",
    "        return \"\"\n",
    "    \n",
    "    def extract_final_answer(self, text: str) -> str:\n",
    "        \"\"\"提取最终答案 - 从 <answer>...</answer> 中提取\"\"\"\n",
    "        # 查找 <answer>...</answer> 块\n",
    "        pattern = r\"<answer>(.*?)</answer>\"\n",
    "        matches = re.findall(pattern, text, re.DOTALL)\n",
    "        if matches:\n",
    "            return matches[-1].strip()  # 取最后一个匹配（应该只有一个）\n",
    "        return \"\"\n",
    "    \n",
    "    def compute_reward(self, trajectory: Trajectory, ground_truth: str) -> float:\n",
    "        format_reward = self.check_format_correctness(trajectory.generated_text)\n",
    "\n",
    "        answer_reward = self.check_answer_correctness(trajectory.final_answer, ground_truth)\n",
    "\n",
    "        total_reward = answer_reward + format_reward\n",
    "\n",
    "        return total_reward\n",
    "\n",
    "    \n",
    "    def check_format_correctness(self, generated_text: str) -> float:\n",
    "        \"\"\"\n",
    "        检查格式正确性\n",
    "        要求:\n",
    "        1. 可以有多轮 think/search/information 循环\n",
    "        2. <answer></answer> 只能出现一次，且在最末尾\n",
    "        3. 所有标签必须成对出现\n",
    "        \"\"\"\n",
    "        # 检查 answer 标签\n",
    "        answer_start_count = generated_text.count(\"<answer>\")\n",
    "        answer_end_count = generated_text.count(\"</answer>\")\n",
    "\n",
    "        # answer 标签必须恰好出现一次\n",
    "        if answer_start_count != 1 or answer_end_count != 1:\n",
    "            return -1.0  # answer 标签数量错误\n",
    "\n",
    "        # 检查 answer 是否在最末尾\n",
    "        answer_start_pos = generated_text.rfind(\"<answer>\")\n",
    "        answer_end_pos = generated_text.rfind(\"</answer>\")\n",
    "\n",
    "        if (\n",
    "            answer_start_pos == -1\n",
    "            or answer_end_pos == -1\n",
    "            or answer_start_pos >= answer_end_pos\n",
    "        ):\n",
    "            return -1.0  # answer 标签位置错误\n",
    "\n",
    "        # 检查 answer 后面是否还有其他内容（除了空白字符）\n",
    "        after_answer = generated_text[answer_end_pos + len(\"</answer>\") :].strip()\n",
    "        if after_answer:\n",
    "            return -1.0  # answer 后面还有内容\n",
    "\n",
    "        # 检查其他标签的配对\n",
    "        tag_pairs = [\n",
    "            (\"<think>\", \"</think>\"),\n",
    "            (\"<search>\", \"</search>\"),\n",
    "            (\"<information>\", \"</information>\"),\n",
    "        ]\n",
    "\n",
    "        for start_tag, end_tag in tag_pairs:\n",
    "            start_count = generated_text.count(start_tag)\n",
    "            end_count = generated_text.count(end_tag)\n",
    "            if start_count != end_count:\n",
    "                return -1.0  # 标签不配对\n",
    "\n",
    "        # 检查是否至少有一个 think 标签\n",
    "        if generated_text.count(\"<think>\") == 0:\n",
    "            return -1.0  # 缺少必需的 think 标签\n",
    "\n",
    "        return 1.0  # 格式完全正确\n",
    "\n",
    "    def check_answer_correctness(self, final_answer: str, ground_truth: str) -> float:\n",
    "        \"\"\"\n",
    "        检查答案正确性\n",
    "        完全一致得1分，否则0分\n",
    "        直接比较，不进行文本标准化\n",
    "        \"\"\"\n",
    "        if not final_answer or not ground_truth:\n",
    "            return 0.0\n",
    "\n",
    "        # 直接比较，完全匹配\n",
    "        if final_answer == ground_truth:\n",
    "            return 1.0\n",
    "        else:\n",
    "            return 0.0\n",
    "    \n",
    "    def compute_advantages(self, rewards: List[float]) -> torch.Tensor:\n",
    "        # 假设每个组是4， 需要组内计算reward； len(reward) == 8\n",
    "        rewards_tensor = torch.tensor(rewards, dtype=torch.float32).to(self.device)\n",
    "\n",
    "        # 如果只有一个样本，直接fanhui\n",
    "        if len(rewards) == 1:\n",
    "            return torch.zeros_like(rewards_tensor)\n",
    "        \n",
    "        mean_reward = torch.mean(rewards_tensor)\n",
    "        std_reward = torch.std(rewards_tensor, unbiased=False) + 1e-8\n",
    "        advantages = (rewards_tensor - mean_reward) / std_reward\n",
    "        # 1 2 3 reward\n",
    "        # 不要生成 1， 鼓励 生成 3\n",
    "        return advantages\n",
    "\n",
    "    def compute_kl_divergence(\n",
    "        self, old_log_probs: torch.Tensor, new_log_probs: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"计算 KL 散度\"\"\"\n",
    "        return torch.mean(torch.exp(old_log_probs) * (old_log_probs - new_log_probs))\n",
    "\n",
    "\n",
    "    def recompute_log_probs(self, trajectories: List[Trajectory]) -> List[torch.Tensor]:\n",
    "        \"\"\"\n",
    "        重新计算轨迹的对数概率\n",
    "        \"\"\"\n",
    "        if not trajectories: return []\n",
    "\n",
    "        all_input_ids = [traj.full_input_ids for traj in trajectories]\n",
    "        all_positions = [traj.generated_positions for traj in trajectories]\n",
    "\n",
    "         # 找到最大长度\n",
    "        max_len = max(len(ids) for ids in all_input_ids)\n",
    "\n",
    "        # Padding 到相同长度（左侧 padding）\n",
    "        padded_ids = []\n",
    "        attention_masks = []\n",
    "        adjusted_positions = []  # 调整后的位置索引\n",
    "\n",
    "        for ids, positions in zip(all_input_ids, all_positions):\n",
    "            pad_len = max_len - len(ids)\n",
    "            # 左侧 padding\n",
    "            padded_ids.append([self.tokenizer.pad_token_id] * pad_len + ids)\n",
    "            attention_masks.append([0] * pad_len + [1] * len(ids))\n",
    "            # 调整位置索引（因为左侧添加了 padding）\n",
    "            adjusted_positions.append([pos + pad_len for pos in positions])\n",
    "        \n",
    "        input_ids = torch.tensor(padded_ids, dtype=torch.long).to(self.device)\n",
    "        attention_mask = torch.tensor(attention_masks, dtype=torch.long).to(self.device)\n",
    "\n",
    "        # 一次性前向传播所有样本\n",
    "        outputs = self.model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits  # [batch_size, seq_len, vocab_size]\n",
    "\n",
    "        # 提取每个样本的 log_probs\n",
    "        all_log_probs = []\n",
    "        for i, (traj, positions) in enumerate(zip(trajectories, adjusted_positions)):\n",
    "            log_probs = []\n",
    "            for pos, token_step in zip(positions, traj.token_steps):\n",
    "                log_prob = F.log_softmax(logits[i, pos], dim=-1)[token_step.token_id]\n",
    "                log_probs.append(log_prob)\n",
    "            all_log_probs.append(torch.stack(log_probs))\n",
    "\n",
    "        return all_log_probs\n",
    "\n",
    "    \n",
    "    def update_policy(self, trajectories: List[Trajectory]) -> Dict[str, float]:\n",
    "            \"\"\"GRPO 策略更新 - 一次性计算所有样本的 loss，避免多次 backward\"\"\"\n",
    "            if not trajectories:\n",
    "                return {\"loss\": 0.0, \"kl_div\": 0.0}\n",
    "\n",
    "            self.model.train()\n",
    "\n",
    "            # 计算奖励和优势\n",
    "            rewards = [traj.reward for traj in trajectories]\n",
    "            advantages = self.compute_advantages(rewards)\n",
    "\n",
    "            # 获取旧的对数概率\n",
    "            old_log_probs_list = []\n",
    "            for traj in trajectories:\n",
    "                old_probs = torch.tensor([step.log_prob for step in traj.token_steps]).to(\n",
    "                    self.device\n",
    "                )\n",
    "                old_log_probs_list.append(old_probs)\n",
    "\n",
    "            update_times = 1\n",
    "            for _ in range(update_times):\n",
    "                # 关键优化：一次性计算所有新的 log_probs\n",
    "                new_log_probs_list = self.recompute_log_probs(trajectories)\n",
    "\n",
    "                # 清空梯度\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                # 收集所有样本的 loss（不在循环中 backward）\n",
    "                all_policy_losses = []\n",
    "                all_kl_divs = []\n",
    "\n",
    "                for i, traj in enumerate(trajectories):\n",
    "                    new_log_probs = new_log_probs_list[i]\n",
    "                    old_log_probs = old_log_probs_list[i]\n",
    "\n",
    "                    if len(old_log_probs) != len(new_log_probs):\n",
    "                        continue\n",
    "\n",
    "                    # 计算概率比\n",
    "                    ratio = torch.exp(new_log_probs - old_log_probs)\n",
    "\n",
    "                    # 扩展优势到所有 token\n",
    "                    traj_advantage = advantages[i].repeat(len(ratio)).to(self.device)\n",
    "\n",
    "                    # PPO 裁剪目标\n",
    "                    surr1 = ratio * traj_advantage\n",
    "                    surr2 = (\n",
    "                        torch.clamp(ratio, 1 - self.clip_epsilon, 1 + self.clip_epsilon)\n",
    "                        * traj_advantage\n",
    "                    )\n",
    "                    policy_loss = -torch.min(surr1, surr2).mean()\n",
    "\n",
    "                    # KL 散度\n",
    "                    kl_div = self.compute_kl_divergence(old_log_probs, new_log_probs)\n",
    "\n",
    "                    all_policy_losses.append(policy_loss)\n",
    "                    all_kl_divs.append(kl_div)\n",
    "\n",
    "                # 一次性计算总 loss 并 backward（关键优化！）\n",
    "                if all_policy_losses:\n",
    "                    total_policy_loss = torch.stack(all_policy_losses).mean()\n",
    "                    total_kl_div = torch.stack(all_kl_divs).mean()\n",
    "                    total_loss = total_policy_loss + self.beta * total_kl_div\n",
    "\n",
    "                    # 只 backward 一次\n",
    "                    total_loss.backward()\n",
    "\n",
    "                    # 梯度裁剪\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), 0.5)\n",
    "\n",
    "                    # 更新参数\n",
    "                    self.optimizer.step()\n",
    "\n",
    "                    # 记录统计信息\n",
    "                    avg_loss = total_loss.item()\n",
    "                    avg_kl = total_kl_div.item()\n",
    "                else:\n",
    "                    avg_loss = 0.0\n",
    "                    avg_kl = 0.0\n",
    "\n",
    "            # 显式清理缓存\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            return {\n",
    "                \"loss\": avg_loss,\n",
    "                \"kl_div\": avg_kl,\n",
    "                \"avg_reward\": np.mean(rewards),\n",
    "                \"beta\": self.beta,\n",
    "            }\n",
    "\n",
    "    def train_step(self, queries: List[str], ground_truths: List[str]) -> Dict[str, float]:\n",
    "        \"\"\"执行一步训练\"\"\"\n",
    "        # 生成轨迹\n",
    "        trajectories = []\n",
    "        for query, truth in zip(queries, ground_truths):\n",
    "            trajectory = self.generate_trajectory(query, max_tokens=500)\n",
    "            trajectory.reward = self.compute_reward(trajectory, truth)\n",
    "            trajectories.append(trajectory)\n",
    "\n",
    "        # 更新策略\n",
    "        metrics = self.update_policy(trajectories)\n",
    "\n",
    "        # 添加统计信息\n",
    "        avg_tokens = np.mean([len(traj.token_steps) for traj in trajectories])\n",
    "        search_count = sum(\n",
    "            1 for traj in trajectories if \"<search>\" in traj.generated_text\n",
    "        )\n",
    "\n",
    "        metrics.update(\n",
    "            {\n",
    "                \"avg_tokens\": avg_tokens,\n",
    "                \"search_trajectories\": search_count / len(trajectories)\n",
    "                if trajectories\n",
    "                else 0,\n",
    "                \"trajectories\": trajectories,  # 保存轨迹用于打印\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # 清理显存\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45298df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_data() -> Tuple[List[str], List[str]]:\n",
    "    # grpo对于一个query会生成多个answer\n",
    "    queries = [\n",
    "        'Who is Luoling?',\n",
    "        'Who is Luoling?',\n",
    "        'Who is Luoling?',\n",
    "        'Who is Luoling?',\n",
    "    ]\n",
    "    answer = [\n",
    "        'Luoling is a person.',\n",
    "        'Luoling is a person.',\n",
    "        'Luoling is a person.',\n",
    "        'Luoling is a person.'\n",
    "    ]\n",
    "    return queries, answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a2c2189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始化 Search-R1 GRPO (Token-level) 训练器...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/root/miniconda3/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练...\n",
      "\n",
      "================================================================================\n",
      "Epoch 1/2000\n",
      "================================================================================\n",
      "\n",
      "[Sample 1] Query: Who is Luoling?\n",
      "Generated Text: BoundingBox:<BoundingBox details are missing. There is no page information to specify a bounding box. Please provide the page number where the bounding box is specified. Continue leading you through the next section of drawing projections.  Per feature, please include the original data such as name, location, or item type. Or, please select the logical character or phrase: Answer: Luoling, a prominent figure in popular culture - a singer-songwriter, actor, and comedian, gained immense popularity for his work in the entertainment industry. He represented Shaanxi Province in the year 2000. Luoling was not only recognized but also received the \"Star of Goodwill\" award from the Chinese government. His real name is Luoxu Feng, but for foreign embassies, his pseudonym was Qiubing Liuhong. Luo Sugar (2005-2009), the main wife of Luoling, tragically passed away in the A-class incident on October 6th in Lanzhou, Xinjiang, when Luoling entered her room. Luoping (2009-2019), an actor, received the Third Prize in \"Golden Cranes Award\" at a talent show. Luengyu (2017-2020), the famous singer Ji Qu and Liu Niu, started to perform independently. Luoming (2019-2021), the descendant of Luoping, passed away due to illness, and his body was cremated on April 21st. Subsequently, his funeral procession was carried out by volunteers and experienced carpenters in Beihai Roaming. Luoning (2022-2022), a film director serving as the executive producer, took center stage, handling the filming of the newly released film \"Apollo with Love and Freedom\" and producing \"Apollo Biophilia.\" In June, she was invited to perform in the scenic spots of Sichuan on the first of the year of the Rat's Alternation moon. Lu Guoqiao (2022-2022), one of the leading domestic undersea fishing teams in China, won the championship in its first undersea fishing competition. If the booth is incomplete, a new one shall be added and a new propagation has occurred. Procedure 2: If the booth is complete but is experiencing an error, set the text as above and notify that one of\n",
      "Final Answer: \n",
      "Reward: -1.00\n",
      "Num Tokens: 500\n",
      "\n",
      "[Sample 2] Query: Who is Luoling?\n",
      "Generated Text: NavigationView{\n",
      "      baseline: 0;\n",
      "      color: 243;\n",
      "      width: 100%;\n",
      "      height: 2px;\n",
      "    }\n",
      "    Aliyun login rich text input\n",
      "    <Filled input-model></Filled>\n",
      "    <com.alibaba.android.header.PermissionDialog PrefDialog type=\"dialog\"\n",
      "                   android:theme=\"@style/DenumiationsUA\"\n",
      "                   android:backgroundRes=\"@color/white-d\"\n",
      "                   android:theme=\"#Common.white_d\" android:maxLines=\"4\"\n",
      "                      android:apiKey=\"@string/api_secret_key\"\n",
      "                      android:theme=\"@style/Firebase\"\n",
      "                      android:theme=\"@style/Empty\">า</i>uche胡oinsr@uo-ltgrolE.onthe dola pour<ul>\n",
      "                  <li onLongClick=\"loadWaterLevel\">将水桶提取</li>\n",
      "                  <li onLongClick=\"loadWaterLevel\">将水桶插回</li>\n",
      "                  <li onLongClick=\"loadWaterLevel\">将水桶拔出</li>\n",
      "                  <li onLongClick=\"loadWaterLevel\">将水桶拉出</li>\n",
      "                  <li onLongClick=\"loadWaterLevel\">将水桶转向</li>\n",
      "                  <li onLongClick=\"loadWaterLevel\">移除水桶</li>\n",
      "                </ul> Use this setting to a menu of menus above any button. The\n",
      "                        position of menues will change sOur menu positions change based on\n",
      "                your request for the position.\n",
      "\n",
      "                Who Is Dadu: You_loves_depart_url=\"#\">Дay forty-six</i>wa\n",
      "      Knowledge</li>\n",
      "      <li onLongClick=\"loginPanduan\" style=\"background-color:yellow\">登录官\n",
      "      djuan</li>\n",
      "      <li onLongClick=\"Download\" style=\"background-color:yellow\">下载水**Rainbow </li>\n",
      "      <li onLongClick=\"prootdialog\" style=\"background-color:yellow\">获取权限对话框</li>\n",
      "      <li onLongClick=\"Reloadplaylist\" style=\"background-color:yellow\">重 雪 曲索回道梅州浸＞$<$leah;<?php session_start();root=\"mysql_InFileServer\" ${'memavmeter$mg5360Rever1y27} ORDER BY id LIMIT 0,9 FROM `log11533_1_11413` GROUP BY user_id LIMIT\n",
      "Final Answer: \n",
      "Reward: -1.00\n",
      "Num Tokens: 500\n",
      "\n",
      "[Sample 3] Query: Who is Luoling?\n",
      "Generated Text: 篇章\n",
      "\n",
      "             我们身边有很多被称为英雄的故事，飞行员许文俊陈月前哥哥儿军救五岁小孩，院长张晋元凯忠卫士救人救母，护士张雪敏救孕妇。日月八卦、天气、技术和操控人工智能的各种防御巨大的机械而不只是一种梦想实现的。也不只是年轻勇敢坚强而不是浮躁宅男果敢自立自然是不愿意做英雄的然而优秀的领导力可以被认为是英雄在决战中以他行之父母之言\"凡事不可自强不休\"厉害才能引导真正的人生灵魂马银在多年军旅生涯当中带领团队以\"奋斗ingo,实现梦想\"的口号走万里山路。\n",
      "\n",
      "             人类也有自己的英雄\n",
      "\n",
      "             过往一批又一批英雄是人类被学界共识认同的焦点小赵来秀秀林见山噶噶金刚卓交叉刑法宣战超规格侦查和暴力的确是不能避免的尤其是在我们人类社会乃至整个工业社会中这个现象是近半世纪的铁牵钢带通过强加着重大的社会责任负于是不可改变的当刘某陈盛同样作为历史标杆代言号每四个西南二区这个地方不仅仅一个群众性的地方是云南西南二区人民极度的和平团结和进步突破一个桎梏以得取大定之契机这就是我们的英雄。\n",
      "            骉<|im_end|>\n",
      "Final Answer: \n",
      "Reward: -1.00\n",
      "Num Tokens: 272\n",
      "\n",
      "[Sample 4] Query: Who is Luoling?\n",
      "Generated Text:  сахươi, chen laooshi, Xin Qiao Xin, LT Conference, Luoling Android, sycxiao, mmv, LinanStreet, Wang Ping, Cheng Ying, Come, and so on.<|im_end|>\n",
      "Final Answer: \n",
      "Reward: -1.00\n",
      "Num Tokens: 46\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Training Metrics:\n",
      "  Loss: -0.0000\n",
      "  KL Div: -0.0000\n",
      "  Avg Reward: -1.0000\n",
      "  Avg Tokens: 329.5\n",
      "  Search Rate: 0.00\n",
      "  Beta: 0.0100\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Epoch 2/2000\n",
      "================================================================================\n",
      "\n",
      "[Sample 1] Query: Who is Luoling?\n",
      "Generated Text: RelativeTo the rules mentioned above, the complete record of Luoling is the Yellow Skyvine Text Record (DSN left from the Noffice-1.19.01.01). The highest obtained knowledge about Luoling is that he was employed by Alibaba Cloud and was responsible for maintaining the Noffice 1.19.01.01 system. The Yellow Skyvine Text Record belongs to the Google Cloud Platform Data Garden, where many Hugging Face models and datasets are catalogued. Therefore, the inputs processed and outputs by it are authorized models certified by Hugging Face, which have been released through the Alibaba Cloud end-to-end self-built AI course. Thus, the red lines of all his texts should go into two groups: the raw utility components, and the research pure components. They should be trained using supervised learning and tested to identify the root of various hardware failures, while also exploring and integrating into the reliability improvement of the Noffice. The red lines also import and reference datasets to perform additional similarity searches. Additionally, Luoling is a pragmatic person with a big heart, and he always meticulously carefully appraises every detail, demonstrating how he overcomes difficulties and difficulties. Luoling has a broad mind, a high ability to learn and a fast work speed, and his hard work and self-awareness are evident from all aspects of his life. No matter how complex his projects will become, he will delve into the best practices he knows and amass rich experience, becoming a significant part of entire technology development. Compared to traditional developers, he prides himself in being more proficient, closer to the algorithmic scale of the industry. He has an excellent and meticulous writing and editing skills, purposing to make every sentence and grammatical sentence perfect. Luoling has a strong sense of responsibility towards his knowledge and experience, and his utmost focus on and dedication to this work showeth how he overcomes difficulties and pain, implementing methods for executing masterful and efficient codes. Luoling is a person with a fearless and proactive attitude, unwilling to take ineffective actions or avoid responsibilities. The rest of the team consists of many heroes like self-proclaimed \"linguist\" helped \"perpetually\", hacker \"slayer\", and \"smart\", nor is he unwary or hesitant towards difficulties. In the context of the Yellow Skyvine Text Record, Luoling's personality traits are meticulously experimented. In the dictionary form, \"Luoling\" is composed of two parts: luoling\n",
      "Final Answer: \n",
      "Reward: -1.00\n",
      "Num Tokens: 500\n",
      "\n",
      "[Sample 2] Query: Who is Luoling?\n",
      "Generated Text: Based on my previous knowledge, Luoling was a famous person in the Chinese sci-fi horror film industry. He played the role of \"Luoling\"—a technology-hungry avenger tasked with rescuing a ragtag group of space prisoners—particularly well in the 1995 Chinese sci-fi horror film \"Internship\". Luoling also appeared in other notable Chinese sci-fi horror films such as \"Zhou De's Star\" and \"Game of Immortals\". The character was later reworked into the 2014 Chinese sequel to \"Internship\", \"Pin Shuang Letter\". Luoling is particularly known for his extensive socioeconomic ties, which is a key element of the character's identity. His complex social media interactions and embrace of unfamiliar cultures, beliefs, and technologies have influenced the portrayal of his character across multiple Asian sci-fi horror films and adapted film franchises. Luoling is recognized for his ability to transcend gender and racial divides, using powerful plots that allow diverse groups of characters to come into conflict while maintaining a focus on emotions and moral drama. Despite the genre's potential for \"zombie\" tropes, Luoling continues to be admired for his storytelling prowess, dedication to exploring the world as his protagonist, and his ability to adapt his avenger character to a wide range of contexts, including games and anime. Luoling also showcased his digital skills and abilities, including his intricate Badass Gorgeous muscle tone and discerning gut feel, in the context of live action film roles. So, incorporating Luoling is a notable achievement in the Chinese sci-fi horror community.<|im_end|>\n",
      "Final Answer: \n",
      "Reward: -1.00\n",
      "Num Tokens: 320\n",
      "\n",
      "[Sample 3] Query: Who is Luoling?\n",
      "Generated Text: relu, visited, Luoling is the original name of Lei Fang, composed of the initial letters of Jingguang Town. Luoling often sends messages to a cluster of provinces that happened to be the same name as Lei Fang. However, since Luoling works at the provincial level and issues important messages that can affect the broader economic development and social stability of provincial organs, it often has to report but rarely receive messages sent from other eastern regions. Therefore, Luoling occasionally searches for messages sent by people from other provinces and sends replies as soon as he receives them. When other people from other provinces or regions contact Luoling, the content they communicate usually touches on the products and services of some brand names, such as \"Dream5G,\" \"TV001,\" or \"G5Plus.\" Luoling is the representative company in the education, mechanical and electrical, retail, catering, and other related industries in Guizhou Province. Luoling promotes its products and solutions with revolutionary technology and soft mechanical and electrical engineering to ensure the quality and weak points of the products with safety, reliability, functionality, and user-friendliness. Luoling continuously innovates and improves market strategy, product innovation, and business efficiency through the development and operation of the products and services of different sub-industries and regions of Guizhou Province. Luoling's representative companies include Guizhou High-tech Internet and Equipment Company, Guizhou Zinc Scrubbing Cutting Tool Industry Company, Guizhou Household Appliances Company, Guizhou Ci Rainbow Company, and others. Luoling's social responsibility is to create a better environment and service for people, promote social culture, territorial cohesion, and overall stability. Luoling is deeply rooted in Guizhou Province, and has provided high-quality products with science and technology and technological content for a long time. Luoling works in the education and living service fields. Luoling actively carries out social public welfare and cultural activities and runs various kind-hearted tygetrics that benefit the local people. Luoling also sets up a Tuju Academy. Luoling has been constantly working since its establishment, and the Tuju Academy fully embodies the core value of Luoling, \"Learning, Aims to Be One, Improve, For the People, Safe and Healthy,\" which not only stimulates the growth of children, nurturing talent, but also creates a safe and harmonious society with the help of parents and teachers. At present, Guizhou Province has become a beautiful and hilly\n",
      "Final Answer: \n",
      "Reward: -1.00\n",
      "Num Tokens: 500\n",
      "\n",
      "[Sample 4] Query: Who is Luoling?\n",
      "Generated Text: RelativeTo WeChat official account, though Luoling was created by Enfukuan, he is generally recognized as the founder of Alibaba Group's governance (securities regulation) group. After Luoling, most major trading venues in the field began to integrate it into their rules and regulations. In 2019, he officially became the former CFO of Alibaba Group after taking over as the interim group president. Luoling has a record of over a decade of experience in corporate governance and financial management, particularly prominent for his role in the acquisition and restructuring of The Mo Yan Group based on debt. He is recognized as a unique visionary in these arenas. Luoling was briefly publicly traded on the Shanghai Stock Exchange, where he operated T-Live. He has a record of \"parity\", with a high return on investment. He has long been a heavy user of our platform, and is currently the largest fee payer. Luoling also tends to have a truly positive attitude toward credit and existing securities, and a long-standing favorite among traders. He received the \"Wang Mou Liang\" award for his positive attitude by the New China Silver Coins Network in 2021. For his leadership and contribution to the development of the industry, Luoling was awarded grants and rewards from financial institutions. He is often in public service and seems to have a passionate and proactive posture to the world. Luoling is the symbol of the People's Bank of China, and the most authoritative and influential financier in China. Luoling talks a lot and likes to comment more than fight or tease, making him one of the most popular people in the WeChat community. (source:  Chinese People's Bank)<|im_end|>\n",
      "Final Answer: \n",
      "Reward: -1.00\n",
      "Num Tokens: 340\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Training Metrics:\n",
      "  Loss: 0.0000\n",
      "  KL Div: 0.0000\n",
      "  Avg Reward: -1.0000\n",
      "  Avg Tokens: 415.0\n",
      "  Search Rate: 0.00\n",
      "  Beta: 0.0100\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Epoch 3/2000\n",
      "================================================================================\n",
      "\n",
      "[Sample 1] Query: Who is Luoling?\n",
      "Generated Text:  BoxDecoratione is Wuhan, China's largest city and national economic center. Luoling is a retired home for soldiers, known for its dual responsibilities of being a residence and a support unit. Luoling is located in the Happy Garden residential area of Wuhan city. Luoling headquarters are located in Luoling Garden, which is her primary residence. Luoling is renowned for her beautiful gardens, lush landscapes, and friendly demeanor, making her a popular tourist attraction. Luoling has a long history and has faced numerous transformation and development, but her charm and kindness have remained unchanged. Luoling is a symbol of the city’s prosperity and progress, and she is beloved by the local community. Luoling is also a source of inspiration for many, and her dedication to serving the people has made her a role model for those who aspire to be loyal and honest. Luoling's progressive attitude and dedication has made her a target for many individuals and groups. Luoling is a role model for those who aspire to be loyal and honest. Luoling is the face of Wuhan, and she is a beloved city icon. Luoling is the pride and joy of Wuhan. Luoling is a symbol of the city's prosperity and progress, and she is beloved by the local community. Luoling is also a source of inspiration for many, and her progressive attitude and dedication have made her a target for many individuals and groups. Luoling is a role model for those who aspire to be loyal and honest. Luoling is the face of Wuhan, and she is a beloved city icon. Luoling is the pride and joy of Wuhan. Luoling is a symbol of the city's prosperity and progress, and she is beloved by the local community. Luoling is also a source of inspiration for many, and her progressive attitude and dedication have made her a target for many individuals and groups. Luoling is a role model for those who aspire to be loyal and honest. Luoling is the face of Wuhan, and she is a beloved city icon. Luoling is the pride and joy of Wuhan. Luoling is a symbol of the city's prosperity and progress, and she is beloved by the local community. Luoling is also a source of inspiration for many, and her progressive attitude and dedication have made her a target for many individuals and groups. Luoling is a role model for those who aspire to be loyal and honest. Luoling is the face of Wuhan, and she is a\n",
      "Final Answer: \n",
      "Reward: -1.00\n",
      "Num Tokens: 500\n",
      "\n",
      "[Sample 2] Query: Who is Luoling?\n",
      "Generated Text:  Luoling, also known as Luoling, is a professional No. 1 hacker and security expert. He has a strong passion for privacy, cybersecurity, and intelligence analysis. Luoling has graduated from Tsinghua University with a degree in computer science and has been involved in various cybersecurity projects in his career. He has also been a consultant and trainer sharing his expertise with enterprises and governments around the world. Luoling has received多项国内外信息安全和技术奖项，并积极推动家庭信息安全，宣传信息安全知识，引导公众知悉安全的重要性。 Luoling is a renowned local hacker and security expert with over 10 years of experience in the field, specializing in penetration testing, network security, and cryptography. He has won numerous awards and recognition for his contributions to cybersecurity, and his work has been widely acknowledged by both academic and industry stakeholders. Luoling is also a passionate advocate for privacy and transparency in the digital world, recognizing the risks of data breaches and cyberattacks and advocating for stronger security measures to protect against them. Luoling lives in Shanghai and has a strong connection with the local cybersecurity scene. He participates in or organizes various cybersecurity events and workshops to promote the importance of cybersecurity in society. Luoling has also been a highly respected figure in the Chinese artificial intelligence community, known for his contributions to AI research and development. Luoling is an active participant in the field of education, particularly in cybersecurity and AI, and serves as a role model for many young和技术人员。 Luoling is known for his expertise in penetration testing, network security, and cryptography, and his work has had a significant impact on the field of cybersecurity. Luoling is also a dedicated advocate for privacy and transparency in the digital world, and recognize the risks of data breaches and cyberattacks and advocating for stronger security measures to protect against them. Luoling is a highly regarded figure in the Chinese artificial intelligence community, known for his contributions to AI research and development. Luoling is an active participant in the field of education, particularly in cybersecurity and AI, and serves as a role model for many young和技术人员。 Luoling is known for his expertise in penetration testing, network security, and cryptography, and his work has had a significant impact on the field of cybersecurity. Luoling is also a dedicated advocate for privacy and transparency in the digital world, and recognize the risks of data breaches and cyberattacks and advocating for stronger security measures to protect against them. Luoling is a highly regarded figure in the Chinese artificial intelligence community, known for\n",
      "Final Answer: \n",
      "Reward: -1.00\n",
      "Num Tokens: 500\n",
      "\n",
      "[Sample 3] Query: Who is Luoling?\n",
      "Generated Text: ReadWrite_Event_36324, Luoling, 14:18, 用户对 Forum 2 内部发生的一起纠纷，引起大家的广泛关注。前沿问题团队迅速判断，影响范围广，涉及多个政府部门和行业企业，需要迅速响应和处理。前沿团队迅速启动应急预案，分组研判，及时调整策略，最终成功地撬动了各方资源，推动了解决问题的进程。在危机处理过程中，前沿团队取得了良好的效果，为集团未来发展提供了坚实的保障。 Luoling, 一个具有敏锐洞察力和卓越团队合作精神的企业家，以数据分析和业务产品为驱动，勇于创新和突破，带领团队在激烈的竞争环境中脱颖而出，为集团的发展贡献了重要的力量。 Luoling, 一个年轻充满激情和创新能力的企业家，以出色的表现和卓越的业绩，被业界广泛认可和推崇，成为了我们集团的优秀领导者。Luoling的出现为企业的发展注入了新的活力，也为集团赢得了更多的荣誉和赞赏。 Luoling, 虽然是一名年轻人，但他的智慧和才华在公司内部得到了充分的展现，成为了公司的重要成员，他的角色和责任在不断转变，但他始终保持积极、负责的工作态度，为公司的未来发展做出了重要贡献。 Luoling, 一个人物，但他的精神和故事深远地影响着我们每一个人。他是一名具有挑战精神和使命感的企业家，他的工作境界和技术技能使他成为了一名备受尊敬的老朋友。 Luoling, 一名平凡的人，但他在团队中的付出和努力却得到了人们的充分尊重和认可，他的生活和工作都在为集团的未来发展提供动力和力量。 Luoling, 他是一个充满活力和创造力的企业家，他的智慧和才华使他成为了我们公司的 backbone，他的实际行动和努力为公司的成功贡献了重要的力量。 Luoling, 一个普通的人，但他用自己的实际行动为公司的成功做出了重要贡献，他的生活和工作都在为集团的未来发展提供动力和力量。 Luoling, 一个普通的人，但他的身上充满了智慧和才华，他的不足之处以及改进的方向也是我们大家关注的焦点。 Luoling, 他的名字虽然普通，但他却以他的智慧和才华为集团的成功做出了重要的贡献，他的生活和工作都在为集团的未来发展提供动力和力量。 Luoling, 一个普通人，但他用自己的实际行动为公司的成功做出了重要贡献，他的生活和工作都在为集团的未来发展提供动力\n",
      "Final Answer: \n",
      "Reward: -1.00\n",
      "Num Tokens: 500\n",
      "\n",
      "[Sample 4] Query: Who is Luoling?\n",
      "Generated Text: RowAt Luo, Member of the Chinese Communist Party, and heads the Political Work Department of the Guangzhou Communist Party Branch. Luo is also the Chairman of the Standing Committee of the Guangzhou Municipal Committee, a Member of the Chinese People's Political Consultative Conference, and a member of the CPPCC of the Guangzhou Municipal Committee. Luo has a strong political stance, pro-advanced, and adheres to the path of socialism with Chinese characteristics. He was UNESCO Goodwill Ambassador in 2016, and also served as the honorary chairman of the People's Friendship Hall in Guangzhou. Luo is known for his dedication to the cause, his courage to fight, and his commitment to public services. He is a role model for generations of colleagues and a true patriot. Luo's contributions have helped to strengthen the party's unity and stabilize the region. He is actively engaged in military and political public service, promoting the development of the party and the nation. Throughout his career, Luo has always been striving to improve his qualities, enhance his capabilities, and uphold the high tradition of the Communist Party of China. Luo is deeply committed to the cause of social stability and development, always maintaining a peaceful and prosperous living environment for the people. Luoling is indeed a shining gem of the Communist Party of China and a truly role model for the country. Luoling's dedication and contributions to society have made him widely recognized by the public and the country. Luoling is a paramount figure in Guangzhou, and his impact on the city's development and the future of the Communist Party of China are incalculable. Luoling is Luoling, Luoling. Luoling is Luoling. Luoling is Luoling. Luoling is Luoling. Luoling is Luoling. Luoling is Luoling. Luoling is Luoling. Luoling is Luoling. Luoling is Luoling. Luoling is Luoling. Luoling is Luoling. Luoling, member of the Communist Party of China, is recognized worldwide for his noble character and significant contributions. Luoling is indeed an exceptionally good man and an outstanding leader, widely recognized as the \"best model of the Communist Party of China.\" Luoling's personal virtues, leadership skills, and qualities have inspired generations of Chinese descendants and ordinary citizens. Luoling's perseverance in struggle and generous service to the public have left a profound impact on the people. Luoling's contributions have been recognized and widely praised by the world, including the United States\n",
      "Final Answer: \n",
      "Reward: -1.00\n",
      "Num Tokens: 500\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Training Metrics:\n",
      "  Loss: -0.0000\n",
      "  KL Div: -0.0000\n",
      "  Avg Reward: -1.0000\n",
      "  Avg Tokens: 500.0\n",
      "  Search Rate: 0.00\n",
      "  Beta: 0.0100\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Epoch 4/2000\n",
      "================================================================================\n",
      "\n",
      "[Sample 1] Query: Who is Luoling?\n",
      "Generated Text:  Luoling is a Chinese character widely used in the Chinese language and literature. He was invented in the mid-16th century and was created by the famous calligrapher and writer Zhang Xuemen. Luoling is a monophthong syllable, meaning that it is a single sound with no vowels or consonants. Luoling is often used to represent characters that are difficult to write in Latin script, such as \"E\" and \"U\". Luoling is also used to represent characters that are difficult to write in the Chinese phonetic script, such as \"Y\" and \"W\". Luoling has been used in advertising, marketing, and other areas of Chinese culture for centuries, and has come to be regarded as a cultural icon. Luoling is also known as 氕 lui, which means \"diminished\" or \"impaired\". Luoling was originally used to represent various Chinese characters, but over time, it became known solely as Luoling, the name of the creator. Luoling has become a national treasure and is considered one of the most important symbols of Chinese culture. Luoling is also known as 水龙滩, which means \"Water Dragon\" or \"Song of Water\" in Hebei Province. Luoling has played a significant role in the development of Chinese culture and has been recognized as a cultural icon by the Chinese government. Luoling has become a symbol of Chinese culture and continues to be an important part of Chinese society. Luoling is a national treasure and a cultural icon in China. Luoling is also known as the \"Dragon\" or \"Water\" character, which has been used in popular culture for generations. Luoling has become a symbol of Chinese culture and has been recognized as a cultural icon by the Chinese government. Luoling is also known as the \"Water\" or \"Dragon\" character, which has been used in popular culture for generations. Luoling has become a symbol of Chinese culture and has been recognized as a cultural icon by the Chinese government. Luoling is also known as the \"Water\" or \"Dragon\" character, which has been used in popular culture for generations. Luoling has become a symbol of Chinese culture and has been recognized as a cultural icon by the Chinese government. Luoling is also known as the \"Water\" or \"Dragon\" character, which has been used in popular culture for generations. Luoling has become a symbol of Chinese culture and has been recognized as a cultural icon by the\n",
      "Final Answer: \n",
      "Reward: -1.00\n",
      "Num Tokens: 500\n",
      "\n",
      "[Sample 2] Query: Who is Luoling?\n",
      "Generated Text:  Luoling is a young entrepreneur and technology entrepreneur from China. He has a Bachelor's degree in computer science and has over 10 years of experience in developing and implementing software solutions. Luoling has been recognized for his innovative ideas and technical achievements, and has been widely recognized in the industry. Luoling is known for his keen intelligence, problem-solving capabilities, and sense of responsibility. Luoling has been active in the technology industry and is committed to using his expertise to create valuable products and services that help people succeed. Luoling is a highly talented and visionary entrepreneur who is dedicated to helping the world thrive through technology. Luoling is known for his willingness to take on new challenges and be mentored by talented individuals in the industry. Luoling is a true example of a successful entrepreneur who has made a positive impact on the world through his innovative ideas and technical achievements. Luoling is a passionate and dedicated entrepreneur who has a strong sense of responsibility and a commitment to using his business skills to solve some of the world's most pressing problems. Luoling is a true leader in the technology industry who has a track-record of creating valuable products and services that help people succeed. Luoling is a true entrepreneur who has a track-record of using his expertise to create valuable products and services that help people succeed. Luoling is a true leader in the technology industry who has a track-record of solving complex problems and creating valuable products and services that help people succeed. Luoling is a true entrepreneur who has a track-record of creating valuable products and services that help people succeed. Luoling is a true leader in the technology industry who has a track-record of using his expertise to create valuable products and services that help people succeed. Luoling is a true entrepreneur who has a track-record of creating valuable products and services that help people succeed. Luoling is a true leader in the technology industry who has a track-record of using his expertise to create valuable products and services that help people succeed. Luoling is a true entrepreneur who has a track-record of creating valuable products and services that help people succeed. Luoling is a true leader in the technology industry who has a track-record of using his expertise to create valuable products and services that help people succeed. Luoling is a true entrepreneur who has a track-record of creating valuable products and services that help people succeed. Luoling is a true leader in the technology industry who has a track-record of using his expertise to create valuable products and services that help people succeed. Luoling\n",
      "Final Answer: \n",
      "Reward: -1.00\n",
      "Num Tokens: 500\n",
      "\n",
      "[Sample 3] Query: Who is Luoling?\n",
      "Generated Text: Luoling, also known as Luoling Kun, is a well-known figure in the internet industry. He is a product developer with a deep understanding of the internet and its applications. Luoling has been involved in the development of several popular internet products, including WeChat and Douyin. He has also been involved in the talent discovery and promotion of internet celebrities. Luoling is known for his innovative thinking and his ability to come up with creative solutions to complex problems. Luoling is a true legend in the internet industry and is celebrated for his contributions to the growth and success of the internet.</esity:5830530606714424801)<|im_end|>\n",
      "Final Answer: \n",
      "Reward: -1.00\n",
      "Num Tokens: 142\n",
      "\n",
      "[Sample 4] Query: Who is Luoling?\n",
      "Generated Text: Luoling, also known as \"Luobin,\" is a member of the Chinese Communist Party. He was a key figure in the founding of the People's Republic of China and played a significant role in the development of the country and its people. Luoling was born in 1955 in a Communist family and grew up in Beijing. He was raised by his father, a Communist Party member, and received an equal education with his brothers. Luoling was ranked 5th in his class and graduated from a Socialist University in 1978. He went on to receive a master's degree in political science from a University in the United States in 1981. After returning to China, he worked as a civil servant and became involved in thePeople's Liberation Army of China. Luoling was a tireless fighter for the country's freedom and was known for his dedication to his duties and his deep love for his country. He was arrested twice for his involvement in the 1970s and 1980s, but was released on bail in 1982. Luoling held high-ranking positions in the government and was influential in the development of the country's politics and economy. He was a prominent figure in the Chinese domestic and international political scene for over four decades and was honored with numerous awards and honors. Luoling was a beloved figure in Chinese society and was widely respected for his courage, dedication, and commitment to his country. Luoling, born in 1955, is a member of the Chinese Communist Party and holds a high-ranking position in the government. He was arrested twice for his involvement in the 1970s and 1980s and was released on bail in 1982. Luoling is a tireless fighter for the country's freedom and was known for his deep love for his country. Luoling was a key figure in the founding of the People's Republic of China and played a significant role in the development of the country and its people. Luoling was born in 1955 in a Communist family and grew up in Beijing. He was raised by his father, a Communist Party member, and received an equal education with his brothers. Luoling was ranked 5th in his class and graduated from a Socialist University in 1978. He went on to receive a master's degree in political science from a University in the United\n",
      "Final Answer: \n",
      "Reward: -1.00\n",
      "Num Tokens: 500\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Training Metrics:\n",
      "  Loss: -0.0000\n",
      "  KL Div: -0.0000\n",
      "  Avg Reward: -1.0000\n",
      "  Avg Tokens: 410.5\n",
      "  Search Rate: 0.00\n",
      "  Beta: 0.0100\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Epoch 5/2000\n",
      "================================================================================\n",
      "\n",
      "[Sample 1] Query: Who is Luoling?\n",
      "Generated Text: Luoling is a character from the \"Luoling Series\" series by the author Liang Yuheng. He is a middle school student who is passionate about science and technology. Luoling is known for his bright imagination and creativity, and he is always eager to solve problems and find solutions. Luoling is a character who is often portrayed as a hero or a hero-like figure in the series, and he is respected by his classmates and teachers. Luoling is a character who is dedicated to his studies and is always eager to learn new things. Luoling is a character who is dedicated to his studies and is always eager to learn new things. Luoling is a character who is dedicated to his studies and is always eager to learn new things. Luoling is a character who is dedicated to his studies and is always eager to learn new things. Luoling is a character who is dedicated to his studies and is always eager to learn new things. Luoling is a character who is dedicated to his studies and is always eager to learn new things. Luoling is a character who is dedicated to his studies and is always eager to learn new things. Luoling is a character who is dedicated to his studies and is always eager to learn new things. Luoling is a character who is dedicated to his studies and is always eager to learn new things. Luoling is a character who is dedicated to his studies and is always eager to learn new things. Luoling is a character who is dedicated to his studies and is always eager to learn new things. Luoling is a character who is dedicated to his studies and is always eager to learn new things. Luoling is a character who is dedicated to his studies and is always eager to learn new things. Luoling is a character who is dedicated to his studies and is always eager to learn new things. Luoling is a character who is dedicated to his studies and is always eager to learn new things. Luoling is a character who is dedicated to his studies and is always eager to learn new things. Luoling is a character who is dedicated to his studies and is always eager to learn new things. Luoling is a character who is dedicated to his studies and is always eager to learn new things. Luoling is a character who is dedicated to his studies and is always eager to learn new things. Luoling is a character who is dedicated to his studies and is always eager to learn new things. Luoling is a character who is dedicated to his\n",
      "Final Answer: \n",
      "Reward: -1.00\n",
      "Num Tokens: 500\n",
      "\n",
      "[Sample 2] Query: Who is Luoling?\n",
      "Generated Text: Luoling is a well-known figure in the gaming industry. He is known for his gaming achievements and his involvement in various gaming events. Luoling has been a critical player in the gaming world, and his contributions to the gaming community have been significant. Luoling is known for his sense of justice and his commitment to promoting the interests of the gaming industry. Luoling is a respected figure in the gaming community and is regarded as a authority in the gaming industry. Luoling is a valuable asset to the gaming industry and his contributions to the gaming community are widely respected. Luoling is a talented and dedicated player in the gaming industry and his contributions to the gaming community are recognized and celebrated. Luoling is a respected and influential figure in the gaming industry and his contributions to the gaming community are widely respected. Luoling is a talented and dedicated player in the gaming industry and his contributions to the gaming community are recognized and celebrated. Luoling is a respected and influential figure in the gaming industry and his contributions to the gaming community are widely respected. Luoling is a talented and dedicated player in the gaming industry and his contributions to the gaming community are recognized and celebrated. Luoling is a respected and influential figure in the gaming industry and his contributions to the gaming community are widely respected. Luoling is a talented and dedicated player in the gaming industry and his contributions to the gaming community are recognized and celebrated. Luoling is a respected and influential figure in the gaming industry and his contributions to the gaming community are widely respected. Luoling is a talented and dedicated player in the gaming industry and his contributions to the gaming community are recognized and celebrated. Luoling is a respected and influential figure in the gaming industry and his contributions to the gaming community are widely respected. Luoling is a talented and dedicated player in the gaming industry and his contributions to the gaming community are recognized and celebrated. Luoling is a respected and influential figure in the gaming industry and his contributions to the gaming community are widely respected. Luoling is a talented and dedicated player in the gaming industry and his contributions to the gaming community are recognized and celebrated. Luoling is a respected and influential figure in the gaming industry and his contributions to the gaming community are widely respected. Luoling is a talented and dedicated player in the gaming industry and his contributions to the gaming community are recognized and celebrated. Luoling is a respected and influential figure in the gaming industry and his contributions to the gaming community are widely respected. Luoling is a talented and dedicated player in the gaming\n",
      "Final Answer: \n",
      "Reward: -1.00\n",
      "Num Tokens: 500\n",
      "\n",
      "[Sample 3] Query: Who is Luoling?\n",
      "Generated Text: Luoling is a well-known figure in the music industry. He is known for his unique style of music and has been influencing the music scene for years. Luoling has been recognized for his contributions to the music industry and has been considered a key figure in the rise of Chinese music. Luoling is known for his ability to create music that is both catchy and memorable, and his influence on the music industry has been significant. Luoling is a man who has been a role model for many in the music industry and has been treated with respect and admiration throughout his career. Luoling is a man who has left a lasting impact on the music industry and has been a recognized figure in the field of music. Luoling is a man who has been a key figure in the rise of Chinese music and has been recognized for his contributions to the industry. Luoling is a man who has left a lasting impact on the music industry and has been a recognized figure in the field of music. Luoling is a man who has been a key figure in the rise of Chinese music and has been recognized for his contributions to the industry. Luoling is a man who has left a lasting impact on the music industry and has been a recognized figure in the field of music. Luoling is a man who has been a key figure in the rise of Chinese music and has been recognized for his contributions to the industry. Luoling is a man who has left a lasting impact on the music industry and has been a recognized figure in the field of music. Luoling is a man who has been a key figure in the rise of Chinese music and has been recognized for his contributions to the industry. Luoling is a man who has left a lasting impact on the music industry and has been a recognized figure in the field of music. Luoling is a man who has been a key figure in the rise of Chinese music and has been recognized for his contributions to the industry. Luoling is a man who has left a lasting impact on the music industry and has been a recognized figure in the field of music. Luoling is a man who has been a key figure in the rise of Chinese music and has been recognized for his contributions to the industry. Luoling is a man who has left a lasting impact on the music industry and has been a recognized figure in the field of music. Luoling is a man who has been a key figure in the rise of Chinese music and has been recognized for his contributions to the industry. Lu\n",
      "Final Answer: \n",
      "Reward: -1.00\n",
      "Num Tokens: 500\n",
      "\n",
      "[Sample 4] Query: Who is Luoling?\n",
      "Generated Text: Luoling, also known as Luoling Chen, is a Chinese internet celebrity and entrepreneur. He was born on June 23, 1988, in Shandong Province. Luoling is widely recognized for his innovative thinking and entrepreneurial spirit. He has won several awards for his creative work, including the China Internet發展 Award. Luoling is also known for his involvement in the development of the Chinese language and its applications. Luoling is a popular figure in the internet industry and has been mentioned in various news and media. Luoling is known for his contributions to the development of Chinese language technology and its applications. Luoling is a forward-thinking and innovative figure in the internet industry. Luoling is a respected figure in the internet industry and has been recognized for his creativity and innovation. Luoling is a influential figure in the internet industry and has been mentioned in various news and media. Luoling is known for his contributions to the development of Chinese language technology and its applications. Luoling is a forward-thinking and innovative figure in the internet industry. Luoling is a respected figure in the internet industry and has been recognized for his creativity and innovation. Luoling is a influential figure in the internet industry and has been mentioned in various news and media. Luoling is known for his contributions to the development of Chinese language technology and its applications. Luoling is a forward-thinking and innovative figure in the internet industry. Luoling is a respected figure in the internet industry and has been recognized for his creativity and innovation. Luoling is a influential figure in the internet industry and has been mentioned in various news and media. Luoling is known for his contributions to the development of Chinese language technology and its applications. Luoling is a forward-thinking and innovative figure in the internet industry. Luoling is a respected figure in the internet industry and has been recognized for his creativity and innovation. Luoling is a influential figure in the internet industry and has been mentioned in various news and media. Luoling is known for his contributions to the development of Chinese language technology and its applications. Luoling is a forward-thinking and innovative figure in the internet industry. Luoling is a respected figure in the internet industry and has been recognized for his creativity and innovation. Luoling is a influential figure in the internet industry and has been mentioned in various news and media. Luoling is known for his contributions to the development of Chinese language technology and its applications. Luoling is a forward-thinking and innovative figure in the internet industry.\n",
      "Final Answer: \n",
      "Reward: -1.00\n",
      "Num Tokens: 500\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Training Metrics:\n",
      "  Loss: -0.0000\n",
      "  KL Div: -0.0000\n",
      "  Avg Reward: -1.0000\n",
      "  Avg Tokens: 500.0\n",
      "  Search Rate: 0.00\n",
      "  Beta: 0.0100\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 56\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     51\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReward: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mcompute_reward(trajectory,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPython is a programming language\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     52\u001b[0m     )\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 56\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 15\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2000\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# 如果是真实环境，那么应该每 x 个一组。（可以通过 构建自己的 Dataset 然后 repeat 实现）\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# for query in queries:\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqueries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mground_truths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m80\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 414\u001b[0m, in \u001b[0;36mSearchR1GRPO.train_step\u001b[0;34m(self, queries, ground_truths)\u001b[0m\n\u001b[1;32m    412\u001b[0m trajectories \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m query, truth \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(queries, ground_truths):\n\u001b[0;32m--> 414\u001b[0m     trajectory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_trajectory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    415\u001b[0m     trajectory\u001b[38;5;241m.\u001b[39mreward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_reward(trajectory, truth)\n\u001b[1;32m    416\u001b[0m     trajectories\u001b[38;5;241m.\u001b[39mappend(trajectory)\n",
      "Cell \u001b[0;32mIn[4], line 78\u001b[0m, in \u001b[0;36mSearchR1GRPO.generate_trajectory\u001b[0;34m(self, query, max_tokens)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_tokens):\n\u001b[1;32m     77\u001b[0m         \u001b[38;5;66;03m# forward\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m         logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :] \u001b[38;5;66;03m# 最后一个logits\u001b[39;00m\n\u001b[1;32m     81\u001b[0m         \u001b[38;5;66;03m# 概率分布\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/utils/generic.py:918\u001b[0m, in \u001b[0;36mcan_return_tuple.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict_passed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    917\u001b[0m     return_dict \u001b[38;5;241m=\u001b[39m return_dict_passed\n\u001b[0;32m--> 918\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    920\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_tuple()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py:449\u001b[0m, in \u001b[0;36mQwen2ForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;129m@can_return_tuple\u001b[39m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;129m@auto_docstring\u001b[39m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Unpack[TransformersKwargs],\n\u001b[1;32m    431\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CausalLMOutputWithPast:\n\u001b[1;32m    432\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;124;03m    Example:\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;124;03m    \"Hey, are you conscious? Can you talk to me?\\nI'm not conscious, but I can talk to you.\"\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;124;03m    ```\"\"\"\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m     outputs: BaseModelOutputWithPast \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/utils/generic.py:1064\u001b[0m, in \u001b[0;36mcheck_model_inputs.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1061\u001b[0m                 monkey_patched_layers\u001b[38;5;241m.\u001b[39mappend((module, original_forward))\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1064\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m original_exception:\n\u001b[1;32m   1066\u001b[0m     \u001b[38;5;66;03m# If we get a TypeError, it's possible that the model is not receiving the recordable kwargs correctly.\u001b[39;00m\n\u001b[1;32m   1067\u001b[0m     \u001b[38;5;66;03m# Get a TypeError even after removing the recordable kwargs -> re-raise the original exception\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m     \u001b[38;5;66;03m# Otherwise -> we're probably missing `**kwargs` in the decorated function\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m     kwargs_without_recordable \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m recordable_keys}\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py:384\u001b[0m, in \u001b[0;36mQwen2Model.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m position_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrotary_emb(hidden_states, position_ids)\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m decoder_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers]:\n\u001b[0;32m--> 384\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdecoder_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(hidden_states)\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m BaseModelOutputWithPast(\n\u001b[1;32m    397\u001b[0m     last_hidden_state\u001b[38;5;241m=\u001b[39mhidden_states,\n\u001b[1;32m    398\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    399\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/modeling_layers.py:94\u001b[0m, in \u001b[0;36mGradientCheckpointingLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning_once(message)\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m---> 94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py:232\u001b[0m, in \u001b[0;36mQwen2DecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_values, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;129m@deprecate_kwarg\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpast_key_value\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpast_key_values\u001b[39m\u001b[38;5;124m\"\u001b[39m, version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4.58\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Unpack[TransformersKwargs],\n\u001b[1;32m    230\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    231\u001b[0m     residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[0;32m--> 232\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_layernorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[1;32m    234\u001b[0m     hidden_states, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn(\n\u001b[1;32m    235\u001b[0m         hidden_states\u001b[38;5;241m=\u001b[39mhidden_states,\n\u001b[1;32m    236\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    243\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py:201\u001b[0m, in \u001b[0;36mQwen2RMSNorm.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    199\u001b[0m variance \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    200\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mrsqrt(variance \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariance_epsilon)\n\u001b[0;32m--> 201\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m \u001b[38;5;241m*\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mto(input_dtype)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1918\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1909\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[1;32m   1911\u001b[0m \u001b[38;5;66;03m# On the return type:\u001b[39;00m\n\u001b[1;32m   1912\u001b[0m \u001b[38;5;66;03m# We choose to return `Any` in the `__getattr__` type signature instead of a more strict `Union[Tensor, Module]`.\u001b[39;00m\n\u001b[1;32m   1913\u001b[0m \u001b[38;5;66;03m# This is done for better interop with various type checkers for the end users.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[38;5;66;03m# See full discussion on the problems with returning `Union` here\u001b[39;00m\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;66;03m# https://github.com/microsoft/pyright/issues/4213\u001b[39;00m\n\u001b[0;32m-> 1918\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m   1919\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m   1920\u001b[0m         _parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"主训练循环\"\"\"\n",
    "    print(\"初始化 Search-R1 GRPO (Token-level) 训练器...\")\n",
    "    trainer = SearchR1GRPO()\n",
    "\n",
    "    # 创建训练数据\n",
    "    queries, ground_truths = create_training_data()\n",
    "\n",
    "    print(\"开始训练...\")\n",
    "    num_epochs = 2000\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # 如果是真实环境，那么应该每 x 个一组。（可以通过 构建自己的 Dataset 然后 repeat 实现）\n",
    "        # for query in queries:\n",
    "        metrics = trainer.train_step(queries, ground_truths)\n",
    "\n",
    "        print(f\"\\n{'=' * 80}\")\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        print(f\"{'=' * 80}\")\n",
    "\n",
    "        # 打印每个样本生成的 tokens\n",
    "        trajectories = metrics.get(\"trajectories\", [])\n",
    "        for i, traj in enumerate(trajectories):\n",
    "            print(f\"\\n[Sample {i + 1}] Query: {traj.query}\")\n",
    "            print(f\"Generated Text: {traj.generated_text}\")\n",
    "            print(f\"Final Answer: {traj.final_answer}\")\n",
    "            print(f\"Reward: {traj.reward:.2f}\")\n",
    "            print(f\"Num Tokens: {len(traj.token_steps)}\")\n",
    "\n",
    "        # 打印训练指标\n",
    "        print(f\"\\n{'─' * 80}\")\n",
    "        print(f\"Training Metrics:\")\n",
    "        print(f\"  Loss: {metrics['loss']:.4f}\")\n",
    "        print(f\"  KL Div: {metrics['kl_div']:.4f}\")\n",
    "        print(f\"  Avg Reward: {metrics['avg_reward']:.4f}\")\n",
    "        print(f\"  Avg Tokens: {metrics['avg_tokens']:.1f}\")\n",
    "        print(f\"  Search Rate: {metrics['search_trajectories']:.2f}\")\n",
    "        print(f\"  Beta: {metrics['beta']:.4f}\")\n",
    "        print(f\"{'=' * 80}\\n\")\n",
    "\n",
    "    # 测试\n",
    "    print(\"\\n测试训练后的模型:\")\n",
    "    test_query = \"What is Python?\"\n",
    "    trajectory = trainer.generate_trajectory(test_query, max_tokens=500)\n",
    "\n",
    "    print(f\"Query: {test_query}\")\n",
    "    print(f\"Generated: {trajectory.generated_text}\")\n",
    "    print(f\"Final Answer: {trajectory.final_answer}\")\n",
    "    print(f\"Tokens: {len(trajectory.token_steps)}\")\n",
    "    print(\n",
    "        f\"Reward: {trainer.compute_reward(trajectory, 'Python is a programming language'):.1f}\"\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
